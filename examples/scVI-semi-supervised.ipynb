{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A semi-supervised framework for the annotation problem\n",
    "\n",
    "**NB**: please refer to the scVI-dev notebook for introduction of the scVI package.\n",
    "\n",
    "In this notebook, we investigate how semi-supervised learning combined with the probabilistic modelling of latent variables in scVI can help address the annotation problem.\n",
    "\n",
    "The annotation problem consists in labelling cells, ie. **inferring their cell types**, knowing only a part of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/scVI\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scvi.dataset import load_datasets\n",
    "from scvi.models import SVAEC\n",
    "from scvi.dataset.utils import get_data_loaders\n",
    "from scvi.train import train_semi_supervised_alternately, train_semi_supervised_jointly\n",
    "from scvi.metrics.classification import compute_accuracy_svc, compute_accuracy_rf\n",
    "from scvi.dataset.utils import get_raw_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle for :  ../scVI-dev/data/cortex-tmp\n",
      "Number of labelled samples :  70\n",
      "Labels and their proportions:  (array([0, 1, 2, 3, 4, 5, 6]), array([10, 10, 10, 10, 10, 10, 10]))\n"
     ]
    }
   ],
   "source": [
    "gene_dataset = load_datasets('cortex')\n",
    "\n",
    "use_batches=False\n",
    "use_cuda=True\n",
    "data_loader_all, data_loader_labelled, data_loader_unlabelled = get_data_loaders(gene_dataset, 10, \n",
    "                                                                                 batch_size=128, pin_memory=use_cuda)\n",
    "\n",
    "# Sanity checks\n",
    "print(\"Number of labelled samples : \",len(data_loader_labelled.sampler.indices))\n",
    "print(\"Labels and their proportions: \",np.unique(gene_dataset.labels[data_loader_labelled.sampler.indices], return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the SVAEC model and train it over 200 epochs. Only labels from the `data_loader_labelled` will be used, but to cross validate the results, the labels of `data_loader_unlabelled` will is used at test time. The accuracy of the `unlabelled` dataset reaches 93% here at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH [0/200]: \n",
      "LL labelled is: 32302.121429\n",
      "Accuracy labelled is: 0.014286\n",
      "LL unlabelled is: 38213.741227\n",
      "Accuracy unlabelled is: 0.026576\n",
      "EPOCH [100/200]: \n",
      "LL labelled is: 1274.317076\n",
      "Accuracy labelled is: 1.000000\n",
      "LL unlabelled is: 1367.440013\n",
      "Accuracy unlabelled is: 0.944804\n",
      "EPOCH [200/200]: \n",
      "LL labelled is: 1193.052344\n",
      "Accuracy labelled is: 1.000000\n",
      "LL unlabelled is: 1259.477050\n",
      "Accuracy unlabelled is: 0.945826\n",
      "Total runtime for 201 epochs is: 80.55557942390442 seconds for a mean per epoch runtime of 0.4007740269845991 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<scvi.metrics.stats.Stats at 0x7f41d657ceb8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svaec = SVAEC(gene_dataset.nb_genes, n_batch=gene_dataset.n_batches * use_batches, n_labels=gene_dataset.n_labels,\n",
    "            use_cuda=use_cuda)\n",
    "train_semi_supervised_jointly(svaec, data_loader_all, data_loader_labelled, data_loader_unlabelled, n_epochs=200, record_freq=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking against other algorithms\n",
    "\n",
    "We can compare ourselves against the random forest and SVM algorithms, where we do grid search with 3-fold cross validation to find the best hyperparameters of these algorithms. This is automatically performed through the functions **`compute_accuracy_svc`** and **`compute_accuracy_rf`**.\n",
    "\n",
    "These functions should be given as input the numpy array corresponding to the equivalent dataloaders, which is the purpose of the **`get_raw_data`** method from `scvi.dataset.utils`.\n",
    "\n",
    "The format of the result is an Accuracy named tuple object giving higher granularity information about the accuracy ie, with attributes:\n",
    "\n",
    "- **unweighted**: the standard definition of accuracy\n",
    "\n",
    "- **weighted**: we might give the same weight to all classes in the final accuracy results. Informative only if the dataset is unbalanced.\n",
    "\n",
    "- **worst**: the worst accuracy score for the classes\n",
    "\n",
    "- **accuracy_classes** : give the detail of the accuracy per classes\n",
    "\n",
    "\n",
    "1 - Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train, labels_train), (data_test, labels_test) = get_raw_data(data_loader_labelled, data_loader_unlabelled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Compute the accuracy score for svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(unweighted=0.8701873935264055, weighted=0.8465908861701248, worst=0.7223650385604113, accuracy_classes=[0.794392523364486, 0.9066666666666666, 0.8857142857142857, 0.7954545454545454, 0.9345679012345679, 0.8869752421959096, 0.7223650385604113])\n"
     ]
    }
   ],
   "source": [
    "accuracy_train , accuracy_test = compute_accuracy_svc(data_train, labels_train,data_test, labels_test)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Compute the accuracy score for rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(unweighted=0.9281090289608177, weighted=0.8978442470701393, worst=0.7954545454545454, accuracy_classes=[0.8738317757009346, 0.9022222222222223, 0.9857142857142858, 0.7954545454545454, 0.9604938271604938, 0.9677072120559742, 0.7994858611825193])\n"
     ]
    }
   ],
   "source": [
    "accuracy_train , accuracy_test = compute_accuracy_rf(data_train, labels_train,data_test, labels_test)\n",
    "print(accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
