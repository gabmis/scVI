{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Tutorial\n",
    "\n",
    "**NB**: please refer to the scVI-dev notebook for introduction of the scVI package.\n",
    "\n",
    "In this notebook, we investigate how semi-supervised learning combined with the probabilistic modelling of latent variables in scVI can help address the annotation problem.\n",
    "\n",
    "The annotation problem consists in labelling cells, ie. **inferring their cell types**, knowing only a part of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/scVI\n"
     ]
    }
   ],
   "source": [
    "cd ~/scVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scvi.dataset import CortexDataset\n",
    "from scvi.models import SCANVI, VAE\n",
    "from scvi.inference import JointSemiSupervisedTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the SVAEC model and train it over 250 epochs. Only labels from the `data_loader_labelled` will be used, but to cross validate the results, the labels of `data_loader_unlabelled` will is used at test time. The accuracy of the `unlabelled` dataset reaches 93% here at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/expression.bin already downloaded\n",
      "Preprocessing Cortex data\n",
      "Finished preprocessing Cortex data\n",
      "training: 100%|██████████| 100/100 [00:42<00:00,  2.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91686541737649063"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_dataset = CortexDataset()\n",
    "\n",
    "use_batches=False\n",
    "use_cuda=True\n",
    "\n",
    "scanvi = SCANVI(gene_dataset.nb_genes, gene_dataset.n_batches, gene_dataset.n_labels)\n",
    "trainer = JointSemiSupervisedTrainer(scanvi, gene_dataset, n_labelled_samples_per_class=10, classification_ratio=100)\n",
    "trainer.train(n_epochs=100)\n",
    "\n",
    "trainer.unlabelled_set.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benchmarking against other algorithms**\n",
    "\n",
    "We can compare ourselves against the random forest and SVM algorithms, where we do grid search with 3-fold cross validation to find the best hyperparameters of these algorithms. This is automatically performed through the functions **`compute_accuracy_svc`** and **`compute_accuracy_rf`**.\n",
    "\n",
    "These functions should be given as input the numpy array corresponding to the equivalent dataloaders, which is the purpose of the **`get_raw_data`** method from `scvi.dataset.utils`.\n",
    "\n",
    "The format of the result is an Accuracy named tuple object giving higher granularity information about the accuracy ie, with attributes:\n",
    "\n",
    "- **unweighted**: the standard definition of accuracy\n",
    "\n",
    "- **weighted**: we might give the same weight to all classes in the final accuracy results. Informative only if the dataset is unbalanced.\n",
    "\n",
    "- **worst**: the worst accuracy score for the classes\n",
    "\n",
    "- **accuracy_classes** : give the detail of the accuracy per classes\n",
    "\n",
    "\n",
    "Compute the accuracy score for rf and svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC score test :\n",
      " Accuracy(unweighted=0.87018739352640551, weighted=0.84659088617012479, worst=0.72236503856041134, accuracy_classes=[0.79439252336448596, 0.90666666666666662, 0.88571428571428568, 0.79545454545454541, 0.9345679012345679, 0.88697524219590962, 0.72236503856041134])\n",
      "\n",
      "RF score train :\n",
      " Accuracy(unweighted=0.8933560477001703, weighted=0.87433300965302296, worst=0.65038560411311053, accuracy_classes=[0.88317757009345799, 0.89777777777777779, 0.99642857142857144, 0.81818181818181823, 0.96049382716049381, 0.91388589881593107, 0.65038560411311053])\n"
     ]
    }
   ],
   "source": [
    "from scvi.inference.annotation import compute_accuracy_rf, compute_accuracy_svc\n",
    "\n",
    "data_train, labels_train = trainer.labelled_set.raw_data()\n",
    "data_test, labels_test = trainer.unlabelled_set.raw_data()\n",
    "svc_scores = compute_accuracy_svc(data_train, labels_train, data_test, labels_test)\n",
    "rf_scores = compute_accuracy_rf(data_train, labels_train, data_test, labels_test)\n",
    "\n",
    "print(\"\\nSVC score test :\\n\", svc_scores[0][1])\n",
    "print(\"\\nRF score train :\\n\", rf_scores[0][1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
